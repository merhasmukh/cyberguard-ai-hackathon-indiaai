{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 07:18:49.932711: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-07 07:18:49.937920: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 07:18:49.990177: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 07:18:50.027423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730944130.082438    6729 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730944130.098822    6729 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 07:18:50.180050: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Load your datasets\n",
    "df_train = pd.read_csv('../../processed_data/processed_train.csv')  \n",
    "df_test = pd.read_csv('../../processed_data/processed_test.csv')  \n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df.to_csv('../../processed_data/full_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "online financial fraud                            76306\n",
       "online and social media related crime             16277\n",
       "any other cyber crime                             14547\n",
       "women/child related crime                          8826\n",
       "cyber attack/ dependent crimes                     4869\n",
       "hacking  damage to computercomputer system etc     1710\n",
       "cryptocurrency crime                                646\n",
       "hacking  damage to computer system etc              592\n",
       "online gambling  betting                            578\n",
       "online cyber trafficking                            244\n",
       "cyber terrorism                                     213\n",
       "ransomware                                           74\n",
       "crime against women & children                        4\n",
       "report unlawful content                               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124887, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_category\n",
       "upi related frauds                                                      35729\n",
       "other                                                                   14547\n",
       "debit/credit card fraud or sim swap fraud                               14357\n",
       "internet banking related fraud                                          11844\n",
       "fraud call/vishing                                                       7628\n",
       "cyber bullying/stalking/sexting                                          5455\n",
       "ewallet related fraud                                                    5385\n",
       "rape/gang rape-sexually abusive content                                  3734\n",
       "fakeimpersonating profile                                                3062\n",
       "profile hacking identity theft                                           2823\n",
       "cheating by impersonation                                                2706\n",
       "sexually obscene material                                                2503\n",
       "sexually explicit act                                                    2087\n",
       "unauthorised access/data breach                                          1484\n",
       "online job fraud                                                         1206\n",
       "demat/depository fraud                                                    983\n",
       "tampering with computer source documents                                  761\n",
       "hacking/defacement                                                        740\n",
       "ransomware attack                                                         720\n",
       "denial of service (dos)/distributed denial of service (ddos) attacks      691\n",
       "malware attack                                                            691\n",
       "sql injection                                                             675\n",
       "data breach/theft                                                         655\n",
       "cryptocurrency fraud                                                      646\n",
       "online gambling  betting                                                  578\n",
       "provocative speech for unlawful acts                                      547\n",
       "child pornography/child sexual abuse material (csam)                      502\n",
       "email hacking                                                             479\n",
       "business email compromise/email takeover                                  380\n",
       "online trafficking                                                        244\n",
       "cyber terrorism                                                           213\n",
       "email phishing                                                            211\n",
       "online matrimonial fraud                                                  170\n",
       "damage to computer systems                                                147\n",
       "defacement/hacking                                                        128\n",
       "ransomware                                                                 74\n",
       "impersonating email                                                        57\n",
       "intimidating email                                                         40\n",
       "computer generated csam/csem                                                2\n",
       "against interest of sovereignty or integrity of india                       1\n",
       "cyber blackmailing & threatening                                            1\n",
       "sexual harassment                                                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sub_category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "online financial fraud                            76306\n",
       "online and social media related crime             16277\n",
       "any other cyber crime                             14547\n",
       "women/child related crime                          8826\n",
       "cyber attack/ dependent crimes                     4869\n",
       "hacking  damage to computercomputer system etc     1710\n",
       "cryptocurrency crime                                646\n",
       "hacking  damage to computer system etc              592\n",
       "online gambling  betting                            578\n",
       "online cyber trafficking                            244\n",
       "cyber terrorism                                     213\n",
       "ransomware                                           74\n",
       "crime against women & children                        4\n",
       "report unlawful content                               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess text data\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df['crimeaditionalinfo'])\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['crimeaditionalinfo'])\n",
    "X = pad_sequences(X, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode category and subcategory labels\n",
    "label_encoder_category = LabelEncoder()\n",
    "y_category = label_encoder_category.fit_transform(df['category'])\n",
    "\n",
    "label_encoder_subcategory = LabelEncoder()\n",
    "y_subcategory = label_encoder_subcategory.fit_transform(df['sub_category'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined dataset into training and testing sets\n",
    "X_train, X_test, y_train_category, y_test_category, y_train_subcategory, y_test_subcategory = train_test_split(\n",
    "    X, y_category, y_subcategory, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24978"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/Desktop/AI_Hackathon/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a multi-output model\n",
    "input_layer = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(max_words, 128, input_length=max_len)(input_layer)\n",
    "lstm_layer = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n",
    "dense_layer = Dense(64, activation='relu')(lstm_layer)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate output layers for each model\n",
    "category_output = Dense(len(np.unique(y_train_category)), activation='softmax')(dropout_layer)\n",
    "subcategory_output = Dense(len(np.unique(y_train_subcategory)), activation='softmax')(dropout_layer)\n",
    "\n",
    "# Define two separate models\n",
    "category_model = Model(inputs=input_layer, outputs=category_output)\n",
    "subcategory_model = Model(inputs=input_layer, outputs=subcategory_output)\n",
    "\n",
    "# Compute class weights for each output\n",
    "category_class_weights = compute_class_weight('balanced', classes=np.unique(y_train_category), y=y_train_category)\n",
    "subcategory_class_weights = compute_class_weight('balanced', classes=np.unique(y_train_subcategory), y=y_train_subcategory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "subcategory_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 56ms/step - accuracy: 0.5019 - loss: 1.5601 - val_accuracy: 0.4471 - val_loss: 1.5038\n",
      "Epoch 2/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 53ms/step - accuracy: 0.5119 - loss: 1.9586 - val_accuracy: 0.5635 - val_loss: 1.2216\n",
      "Epoch 3/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 50ms/step - accuracy: 0.5355 - loss: 1.5742 - val_accuracy: 0.5649 - val_loss: 1.1677\n",
      "Epoch 4/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 50ms/step - accuracy: 0.5313 - loss: 1.2843 - val_accuracy: 0.5473 - val_loss: 1.2334\n",
      "Epoch 5/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 51ms/step - accuracy: 0.5557 - loss: 1.4510 - val_accuracy: 0.5479 - val_loss: 1.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "category_model.fit(\n",
    "    X_train, y_train_category,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test, y_test_category),\n",
    "    class_weight=dict(enumerate(category_class_weights))\n",
    ")\n",
    "\n",
    "# Save the entire model to a file\n",
    "category_model.save('category_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 51ms/step - accuracy: 0.2104 - loss: 2.3780 - val_accuracy: 0.3256 - val_loss: 2.2129\n",
      "Epoch 2/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 53ms/step - accuracy: 0.2829 - loss: 2.1115 - val_accuracy: 0.3327 - val_loss: 2.1592\n",
      "Epoch 3/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 53ms/step - accuracy: 0.3147 - loss: 2.3114 - val_accuracy: 0.3157 - val_loss: 2.2162\n",
      "Epoch 4/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 53ms/step - accuracy: 0.3264 - loss: 2.1440 - val_accuracy: 0.3568 - val_loss: 2.1099\n",
      "Epoch 5/5\n",
      "\u001b[1m3123/3123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 54ms/step - accuracy: 0.3353 - loss: 2.0888 - val_accuracy: 0.3466 - val_loss: 2.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "subcategory_model.fit(\n",
    "    X_train, y_train_subcategory,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test, y_test_subcategory),\n",
    "    class_weight=dict(enumerate(subcategory_class_weights))\n",
    ")\n",
    "# Save the entire model to a file\n",
    "subcategory_model.save('subcategory_model_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the label encoders to files\n",
    "with open('label_encoder_category.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder_category, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('label_encoder_subcategory.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder_subcategory, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Category: any other cyber crime, Subcategory: business email compromise/email takeover\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess and classify new text\n",
    "def classify_text(text):\n",
    "    # Tokenize and pad the input text\n",
    "    text_sequence = tokenizer.texts_to_sequences([text])\n",
    "    text_padded = pad_sequences(text_sequence, maxlen=max_len)\n",
    "\n",
    "    # Make predictions\n",
    "    category_pred= category_model.predict(text_padded)\n",
    "    subcategory_pred=subcategory_model.predict(text_padded)\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    category_index = category_pred.argmax(axis=-1)[0]\n",
    "    subcategory_index = subcategory_pred.argmax(axis=-1)[0]\n",
    "\n",
    "    # Decode the labels\n",
    "    category_label = label_encoder_category.inverse_transform([category_index])[0]\n",
    "    subcategory_label = label_encoder_subcategory.inverse_transform([subcategory_index])[0]\n",
    "\n",
    "    return category_label, subcategory_label\n",
    "\n",
    "# Example usage\n",
    "new_text = \"In apna Job I have applied for job interview for telecalling and the resource management wrote that twelve hundred will be charged for security amount of laptop and work from home when I have given interview on the given address next day they charged twelve hundred and six hundred more money in the name of insurance after that they have referred me to the job calling there is no work of laptop neither a work from home kindly please take action against it as soon as possible and if possible please help me to recover my financial loss\"\n",
    "category, subcategory = classify_text(new_text)\n",
    "print(f\"Category: {category}, Subcategory: {subcategory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
